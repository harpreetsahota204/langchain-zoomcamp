{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLHdOOSx2iBLDfA8jqRCIJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"MMIHoEWltRl1","executionInfo":{"status":"ok","timestamp":1696708859921,"user_tz":300,"elapsed":13591,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"outputs":[],"source":["%%capture\n","!pip install langchain openai faiss-cpu tiktoken"]},{"cell_type":"code","source":["import os\n","import getpass\n","from typing import Dict, Any"],"metadata":{"id":"-8GnGBaWuk8f","executionInfo":{"status":"ok","timestamp":1696712959923,"user_tz":300,"elapsed":1,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyODY2mrumVA","executionInfo":{"status":"ok","timestamp":1696708867593,"user_tz":300,"elapsed":7695,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"317c4ba2-d75d-4598-fa57-cc769ce42a30"},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Your OpenAI API Key:··········\n"]}]},{"cell_type":"markdown","source":["# Zero shot prompting\n","\n","Large Language Models possess a notable feature: zero-shot prompting.\n","\n","Zero-shot prompting involves asking the model to perform a task without providing it with specific examples beforehand. This allows them to generate responses to prompts without requiring specific examples or prior training. Their vast training data enables LLMs to execute tasks \"zero-shot.\"\n","\n","For example, to classify a text as neutral, negative, or positive, one might prompt, \"Classify the text into neutral, negative, or positive,\" and the model could respond with \"Neutral\" for a statement like \"I think the vacation is okay.\"\n","\n","If zero-shot prompting doesn't produce satisfactory outcomes, it's recommended to include demonstrations or examples in the prompt, shifting towards few-shot prompting."],"metadata":{"id":"Fr-dYwcwuoHQ"}},{"cell_type":"code","source":["from langchain.llms import OpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain"],"metadata":{"id":"vPheyNVI3OvL","executionInfo":{"status":"ok","timestamp":1696711263042,"user_tz":300,"elapsed":130,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class ZeroShotChain:\n","    \"\"\"\n","    A class to facilitate zero-shot tasks\n","\n","    Attributes:\n","        llm: An instance of an LLM.\n","    \"\"\"\n","\n","    def __init__(self, llm: Any) -> None:\n","        \"\"\"\n","        Initializes the ZeroShotChain with the provided LLM instance.\n","\n","        Args:\n","            llm: An instance of an LLM.\n","        \"\"\"\n","        self.llm = llm\n","\n","    def create_prompt(self, template: str) -> PromptTemplate:\n","        \"\"\"\n","        Creates a prompt from the provided template.\n","\n","        Args:\n","            template: A string template for creating the prompt.\n","\n","        Returns:\n","            An instance of the created prompt.\n","        \"\"\"\n","        return PromptTemplate.from_template(template)\n","\n","    def create_chain(self, prompt: str) -> LLMChain:\n","        \"\"\"\n","        Creates an LLMChain using the provided prompt.\n","\n","        Args:\n","            prompt: An instance of the created prompt.\n","\n","        Returns:\n","            An instance of the LLMChain.\n","        \"\"\"\n","        return LLMChain(llm=self.llm, prompt=prompt, verbose=True)\n","\n","    def run(self, template: str, user_input: Dict[str, str]) -> str:\n","        \"\"\"\n","        Runs the zero-shot task using the provided template and user input.\n","\n","        Args:\n","            template: A string template for creating the prompt.\n","            user_input: A dictionary containing the user input for the task.\n","\n","        Returns:\n","            The result of the zero-shot task.\n","        \"\"\"\n","        prompt = self.create_prompt(template)\n","        chain = self.create_chain(prompt)\n","        return chain.run(user_input)"],"metadata":{"id":"Dn74pz_h-QcK","executionInfo":{"status":"ok","timestamp":1696713044137,"user_tz":300,"elapsed":158,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# Initialize the llm\n","llm_instance = OpenAI()\n","\n","# Create an instance of the ZeroShotChain class with the LLM instance.\n","chain = ZeroShotChain(llm_instance)"],"metadata":{"id":"Ns_jRMWr-ujb","executionInfo":{"status":"ok","timestamp":1696713441908,"user_tz":300,"elapsed":250,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# Define the template and user input for the sarcasm classification task.\n","sarcasm_template = \"\"\"Classify the user statement, delimited by < >, as sarcastic or not sarcastic.\n","User statement: <{statement}>\n","\"\"\"\n","sarcasm_input = {\"statement\": \"Oh, yippe! Another flat tire.\"}\n","\n","# Run the sarcasm classification task.\n","sarcasm_result = chain.run(sarcasm_template, sarcasm_input)\n","print(sarcasm_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2mJj3DQAHTM","executionInfo":{"status":"ok","timestamp":1696713442821,"user_tz":300,"elapsed":388,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"308db345-27e5-4291-8d9e-771ceb28ff61"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mClassify the user statement, delimited by < >, as sarcastic or not sarcastic.\n","User statement: <Oh, yippe! Another flat tire.>\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","Sarcastic\n"]}]},{"cell_type":"markdown","source":["Named Entity Recognition (NER) is a task where the model identifies and classifies named entities in a text into predefined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc."],"metadata":{"id":"wNgQYSxyzh_Q"}},{"cell_type":"code","source":["# Define the template and user input for the named entity recognition task.\n","entities_template = \"\"\"Identify and categorize the named entities in the text delimited by <>.\n","Text: <{statement}>\n","\"\"\"\n","entities_input = {\"statement\": \"Barack Obama was the 44th president of the United States. He was born in Honolulu, Hawaii, on August 4, 1961. Before his presidency, he attended Harvard Law School.\"}\n","\n","# Run the named entity recognition task.\n","entities_result = chain.run(entities_template, entities_input)\n","\n","print(entities_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPBaGwSXziHa","executionInfo":{"status":"ok","timestamp":1696713144450,"user_tz":300,"elapsed":860,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"b4c2d6d5-50a9-4b92-f731-f54f26efb759"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mIdentify and categorize the named entities in the text delimited by <>.\n","Text: <Barack Obama was the 44th president of the United States. He was born in Honolulu, Hawaii, on August 4, 1961. Before his presidency, he attended Harvard Law School.>\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","Named Entities: \n","Person: Barack Obama\n","Place: United States, Honolulu, Hawaii\n","Title: 44th president\n","Institution: Harvard Law School\n","Date: August 4, 1961\n"]}]},{"cell_type":"markdown","source":["Zero-shot prompting has limitations that make it unsuitable for some use cases.\n","\n","It limits our control over the generated output, may not work for complex tasks, and may struggle with specialized domains.\n","\n","It is usually used for short-form text and may not work well for longer-form text."],"metadata":{"id":"XTJcSFl-5jUX"}}]}