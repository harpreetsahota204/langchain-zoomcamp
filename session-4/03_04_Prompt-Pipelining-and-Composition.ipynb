{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSIFy9YDFDjcf4526f8mcz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sk4lfY0zCsa5"},"outputs":[],"source":["%%capture\n","!pip install langchain openai"]},{"cell_type":"code","source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_moU87efUosB","executionInfo":{"status":"ok","timestamp":1696505165731,"user_tz":300,"elapsed":4060,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"a4b95d23-5f5d-4c67-e102-359459c71b65"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Your OpenAI API Key:··········\n"]}]},{"cell_type":"markdown","source":["# Prompt Pipelining Overview\n","\n","Prompt pipelining is a powerful tool designed for those who seek a modular and efficient approach to prompt design.\n","\n","\n","## Here are some common cases where prompt pipelining can be useful:\n","\n"," - Reusing prompt components like introductions, instructions, examples, etc. across multiple prompts. Prompt pipelining allows easily reusing these modular blocks.\n","\n"," - Splitting up a long prompt into smaller logical chunks. This can make prompts more readable and maintainable.\n","\n"," - Dynamically assembling prompts based on conditionals or other logic. You can build prompts on the fly from reusable parts.\n","\n"," - Creating prompts in a loop by appending to an existing base prompt. Useful for things like few-shot learning prompts.\n","\n"," - Mixing static text with templates containing variables. The static text can provide structure while the templates inject dynamic content.\n","\n"," - Composing chat prompts from message templates and static messages. Each piece gets appended as a new message.\n","\n"," - Building up prompts from user provided components for customization. Prompt pipelining allows prompts to be assembled from modular parts.\n","\n"," - Any situation where you want to build up prompts in a reusable composable way, prompt pipelining provides a clean interface for that.\n","\n","## String Prompt Pipelining\n","\n","For string prompts, templates are interconnected in sequence.\n","\n","You have the liberty to utilize either direct prompts or strings.\n","\n","However, it's essential to note that the initial element in the sequence should always be a prompt."],"metadata":{"id":"0ed8MD_LUp6I"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","prompt = (\n","    PromptTemplate.from_template(\"I'm heading to {destination}. \")\n","    + \"Recommend a great {activity} spot!\")\n","\n","prompt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXzIc8jCXiob","executionInfo":{"status":"ok","timestamp":1696505192385,"user_tz":300,"elapsed":542,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"6e550cfd-5be0-4672-8f7e-62d6b50c4b5d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['destination', 'activity'], template=\"I'm heading to {destination}. Recommend a great {activity} spot!\")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["prompt = prompt + \"\\n\\nAlso, any local delicacies I should try?\"\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1wpoDv7l3Wg","executionInfo":{"status":"ok","timestamp":1696505193647,"user_tz":300,"elapsed":164,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"8a8f3b91-d36e-4b79-c4a8-bd52775e4425"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['destination', 'activity'], template=\"I'm heading to {destination}. Recommend a great {activity} spot!\\n\\nAlso, any local delicacies I should try?\")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["prompt.format(destination=\"Punjab\", activity=\"dining\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"XVbMS46yYIwO","executionInfo":{"status":"ok","timestamp":1696505194047,"user_tz":300,"elapsed":4,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"9c1a02b1-8e54-4e9c-a62e-ad3508b555fe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I'm heading to Punjab. Recommend a great dining spot!\\n\\nAlso, any local delicacies I should try?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### The key differences between prompt pipelining and multi-input prompts are:\n","\n"," - Prompt pipelining composes multiple prompts/strings into a single final prompt. Multi-input prompts allow passing multiple inputs to a single prompt template.\n","\n"," - With pipelining, each component can be formatted independently before joining. Multi-input just formats a single template.\n","\n"," - Pipelining joins components into a linear sequence. Multi-input prompts are a single template handling multiple inputs.\n","\n"," - Pipelining allows reuse of components like introductions, examples, etc. Multi-input is focused on handling multiple query inputs.\n","\n"," - Pipelining output is a single prompt. Multi-input output is the completion based on multiple inputs.\n","\n"," - Pipelining lets you build up prompts modularly. Multi-input is one template handling multiple inputs.\n","\n","In summary, prompt pipelining composes multiple prompt components into one final prompt in a linear sequence. Multi-input prompts allow a single template to handle multiple input variables in parallel. Pipelining focuses on modular prompt building, while multi-input handles multiple query inputs."],"metadata":{"id":"kCuU15Zsb6-E"}},{"cell_type":"markdown","source":["# Use in a chain"],"metadata":{"id":"vWKXtrGIYPjX"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.chains import LLMChain"],"metadata":{"id":"sgGCg2s8YtqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ChatOpenAI()\n","chain = LLMChain(llm=model, prompt=prompt)\n","print(chain.run(destination=\"Punjab\", activity=\"dining\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8-qiXIAYu7Q","executionInfo":{"status":"ok","timestamp":1696505214262,"user_tz":300,"elapsed":9919,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"cc940725-efd6-4b27-ce18-5caf975430a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["If you're heading to Punjab, one great dining spot you should try is Kesar Da Dhaba in Amritsar. It is a famous restaurant known for its authentic Punjabi cuisine and has been serving delicious food since 1916.\n","\n","When it comes to local delicacies, Punjab offers a range of mouthwatering dishes. Here are a few must-try delicacies:\n","\n","1. Makki di Roti and Sarson da Saag: This is a classic Punjabi dish made with cornbread (makki di roti) served with a spicy mustard greens curry (sarson da saag). It's a must-try during the winter season.\n","\n","2. Butter Chicken: A popular dish worldwide, this creamy and flavorful chicken curry is a Punjabi specialty. It's best enjoyed with naan or rice.\n","\n","3. Amritsari Fish: If you're a seafood lover, don't miss out on trying Amritsari fish. It's a deep-fried fish marinated in a flavorful blend of spices, perfect for satisfying your taste buds.\n","\n","4. Chole Bhature: This is a popular Punjabi breakfast dish. Chole is spicy chickpea curry, and bhature is a deep-fried bread made with refined flour. It's a delicious combination that you must try.\n","\n","5. Lassi: Punjab is famous for its refreshing and creamy lassi. It's a traditional yogurt-based drink available in various flavors like sweet, salted, or with fruits. It's perfect for beating the heat.\n","\n","These are just a few delicacies, but Punjab has a lot more to offer in terms of food. Enjoy exploring the vibrant and flavorful cuisine of Punjab!\n"]}]},{"cell_type":"code","source":["prompt = prompt +\" How should I greet the locals in a friendly, informal colloquial manner?\"\n","chain = LLMChain(llm=model, prompt=prompt)\n","print(chain.run(destination=\"Punjab\", activity=\"dining\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7COZydQl2gz","executionInfo":{"status":"ok","timestamp":1696505223292,"user_tz":300,"elapsed":5003,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"860b3b87-0858-4a05-d086-b937c3afb40c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["If you're heading to Punjab, I highly recommend trying out \"Kesar Da Dhaba\" in Amritsar. It is a famous dining spot known for its delicious Punjabi cuisine and traditional flavors.\n","\n","When it comes to local delicacies, you must try the famous \"Sarson Ka Saag\" (a mustard greens dish) with \"Makki Ki Roti\" (a corn flour bread). Another must-try is \"Chole Bhature\" (spiced chickpeas with fried bread), which is a popular Punjabi dish.\n","\n","To greet the locals in a friendly, informal colloquial manner, you can use the phrase \"Sat Sri Akal.\" It is a common Punjabi greeting that means \"God is the ultimate truth.\" It is widely used and is sure to make the locals feel warm and welcomed.\n"]}]},{"cell_type":"markdown","source":["# Example usecase"],"metadata":{"id":"V4WgevnuoYIO"}},{"cell_type":"code","source":["class TravelChatbot:\n","    def __init__(self, base_template):\n","        self.model = ChatOpenAI()\n","        self.base_prompt = PromptTemplate.from_template(base_template)\n","\n","    def append_to_prompt(self, additional_text):\n","        self.base_prompt += additional_text\n","\n","    def run_chain(self, destination, activity):\n","        chain = LLMChain(llm=self.model, prompt=self.base_prompt)\n","        return chain.run(destination=destination, activity=activity)\n","\n","# Usage\n","base_template = \"I'm heading to {destination}. Recommend a great {activity} spot!\"\n","chatbot = TravelChatbot(base_template)\n","# Basic prompt\n","chatbot.run_chain(destination=\"Punjab\", activity=\"dining\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"_BdVa1z2l2X0","executionInfo":{"status":"ok","timestamp":1696505235231,"user_tz":300,"elapsed":3696,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"03a5d9d3-fb22-41f6-9885-0628c9d42b54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"If you're heading to Punjab, I would highly recommend trying out 'Kesar Da Dhaba' in Amritsar. It is a renowned restaurant that has been serving delicious Punjabi cuisine since 1916. Their specialty is the 'Dal Makhani' - a rich and creamy lentil dish, along with other authentic Punjabi delicacies like 'Butter Chicken', 'Amritsari Kulcha', and 'Lassi' (a traditional Punjabi drink). The rustic ambiance and traditional Punjabi hospitality make it a must-visit dining spot for an authentic culinary experience in Punjab.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Append more to the prompt and run again\n","chatbot.append_to_prompt(\"\\n\\nAlso, any local delicacies I should try?\")\n","print(chatbot.run_chain(destination=\"Punjab\", activity=\"dining\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PvagxTLl2PF","executionInfo":{"status":"ok","timestamp":1696505245852,"user_tz":300,"elapsed":8009,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"dccd1730-1c05-4d21-e614-073700c3795d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["If you're heading to Punjab, one great dining spot to try is Kesar Da Dhaba in Amritsar. It is a famous and iconic restaurant known for its delicious Punjabi cuisine.\n","\n","As for local delicacies, here are a few you should definitely try:\n","\n","1. Amritsari Kulcha: This is a popular Punjabi dish, a type of stuffed bread usually served with chole (chickpea curry) and a side of pickles.\n","\n","2. Makki di Roti and Sarson da Saag: This is a traditional Punjabi dish made with cornmeal flatbread (makki di roti) and a spicy mustard greens curry (sarson da saag). It's a must-try during the winter season.\n","\n","3. Butter Chicken: A classic Punjabi dish, butter chicken is a rich and creamy tomato-based chicken curry. It is usually served with naan or rice.\n","\n","4. Lassi: A refreshing Punjabi drink made with yogurt, water, and sometimes flavored with cardamom or mango. It is a perfect accompaniment to your meals.\n","\n","5. Paneer Tikka: This is a popular vegetarian dish made with marinated and grilled cottage cheese, served with mint chutney.\n","\n","These are just a few of the many delicious dishes Punjab has to offer. Enjoy your trip and the culinary delights of the region!\n"]}]},{"cell_type":"code","source":["chatbot.append_to_prompt(\" How should I greet the locals in a friendly, informal, jolly colloquial manner?\")\n","chatbot.run_chain(destination=\"Punjab\", activity=\"dining\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"ufMFRyBnltpk","executionInfo":{"status":"ok","timestamp":1696505271974,"user_tz":300,"elapsed":6758,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"bc53c6cc-b8c9-424c-a2e8-3112d476dcd0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'If you\\'re heading to Punjab, one great dining spot you should try is Kesar Da Dhaba in Amritsar. It is a popular restaurant known for its delicious Punjabi cuisine, especially their signature dish, Dal Makhani.\\n\\nWhen it comes to local delicacies, you must try Makki di Roti (cornbread) with Sarson da Saag (mustard greens curry), Butter Chicken, Chole Bhature (spiced chickpeas with fried bread), and Lassi (a refreshing yogurt-based drink). These are some of the famous Punjabi dishes that will give you a true taste of the region.\\n\\nTo greet the locals in a colloquial manner, you can say \"Sat Sri Akal\" which means \"May God be with you.\" It\\'s a common and respectful way to greet people in Punjab.\\n\\nTo greet the locals in a friendly, informal, and jolly colloquial manner, you can use \"Ki haal hai?\" which translates to \"How are you?\" and is widely used among friends and acquaintances. This will help you strike up a friendly conversation and make the locals feel more comfortable with you.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Chat Prompt Pipeline\n","\n","A chat prompt is made up a of a list of messages. Purely for developer experience, we've added a convinient way to create these prompts. In this pipeline, each new element is a new message in the final prompt.\n","\n","### Key Insights into Chat Prompt Pipelining in Langchain:\n","\n","Composition: Chat prompt pipelining facilitates the creation of chat prompts using reusable message components. Each addition to the pipeline translates to a new message in the final chat prompt.\n","\n","Versatility: You can seamlessly integrate static message objects, such as HumanMessage and AIMessage, with variable-containing message templates.\n","\n","End Result: The culmination is a unified ChatPromptTemplate, primed for formatting and integration into a chain. This structure promotes the effortless reuse of components, including instructions and examples.\n","\n","Modularity: This approach champions the dynamic construction of chat prompts using modular blocks, ensuring flexibility and efficiency.\n","\n","So in summary, chat prompt pipelining composes chat prompts from reusable message templates and static messages. It allows dynamically constructing prompts from logical blocks in a user friendly way. The end result is a single reusable ChatPromptTemplate.\n","\n"],"metadata":{"id":"3ySTTr9VYx1f"}},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n","from langchain.schema import HumanMessage, AIMessage, SystemMessage\n","\n","# Setting the scene with a Cockney-themed system message\n","prompt = SystemMessage(content=\"Welcome to the East End Cockney Chat! 🇬🇧\")\n","\n","# Constructing a chat flow with dry humour\n","new_prompt = (\n","    prompt\n","    + HumanMessage(content=\"Alright, guv'nor?\")\n","    + AIMessage(content=\"Not too shabby. Did you hear about the London fog?\")\n","    + \"{input}\"\n",")\n","\n","# Formatting the chat with the user's response\n","new_prompt.format_messages(input=\"No, what about it?\")\n","print(new_prompt)\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import LLMChain\n","\n","model = ChatOpenAI()\n","\n","chain = LLMChain(llm=model, prompt=new_prompt)\n","\n","# Running the chatbot to get the punchline\n","response = chain.run(\"No, what about it?\")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"RK4T0u4Io4S6","executionInfo":{"status":"ok","timestamp":1696505290932,"user_tz":300,"elapsed":1780,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"897cef4a-a78b-474c-d0ab-df24e65730e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input_variables=['input'] messages=[SystemMessage(content='Welcome to the East End Cockney Chat! 🇬🇧'), HumanMessage(content=\"Alright, guv'nor?\"), AIMessage(content='Not too shabby. Did you hear about the London fog?'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))]\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Well, the fog's thicker than a proper pea soup these days! Can't see my own two feet, I tell ya. Makes it a right challenge to get around town.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n","from langchain.schema import HumanMessage, AIMessage, SystemMessage\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import LLMChain\n","\n","class CockneyChatbot:\n","    def __init__(self, base_template):\n","        self.model = ChatOpenAI()\n","        self.base_prompt = ChatPromptTemplate.from_template(base_template)\n","\n","    def append_to_prompt(self, message_type, content):\n","        if message_type == \"human\":\n","            self.base_prompt += HumanMessage(content=content)\n","        elif message_type == \"ai\":\n","            self.base_prompt += AIMessage(content=content)\n","        else:\n","            raise ValueError(\"Invalid message type\")\n","\n","    def run_chain(self, input_message):\n","        chain = LLMChain(llm=self.model, prompt=self.base_prompt)\n","        return chain.run(input=input_message)\n","\n","# Usage\n","base_template = \"Welcome to the East End Cockney Chat! 🇬🇧\"\n","chatbot = CockneyChatbot(base_template)"],"metadata":{"id":"SfIe-iO6pEqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chatbot.append_to_prompt(\"human\", \"Alright, guv'nor?\")\n","chatbot.append_to_prompt(\"ai\", \"Not too shabby. Did you hear about the London fog?\")\n","print(chatbot.run_chain((\"human\",\"No, what about it?\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKzHhlXSqGIj","executionInfo":{"status":"ok","timestamp":1696505294582,"user_tz":300,"elapsed":1195,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"b7902024-8610-4d6c-f634-25b82f7cc5a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Aye, I 'eard about it. Thick as pea soup, it was. Couldn't see me own hand in front of me face!\n"]}]},{"cell_type":"code","source":["chatbot.append_to_prompt(\"ai\", \"It mist the bus this morning.\")\n","print(chatbot.run_chain(\"That's a proper knees-up!\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxpxhKR9qGQv","executionInfo":{"status":"ok","timestamp":1696505296535,"user_tz":300,"elapsed":1593,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"6d818423-a57d-4b0a-b840-d5834a68b372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Aye, it's a proper pea-souper out there, innit? Can't see a bloomin' thing!\n"]}]},{"cell_type":"code","source":["chatbot.base_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0hyKdXuqGcE","executionInfo":{"status":"ok","timestamp":1696505297849,"user_tz":300,"elapsed":163,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"075de258-3eb1-4db9-bcca-d5f9508791c5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptTemplate(input_variables=[], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Welcome to the East End Cockney Chat! 🇬🇧')), HumanMessage(content=\"Alright, guv'nor?\"), AIMessage(content='Not too shabby. Did you hear about the London fog?'), AIMessage(content='It mist the bus this morning.')])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Prompt Composition\n","\n","This can be useful when you want to reuse parts of prompts. This can be done with a PipelinePrompt. A PipelinePrompt consists of two main parts:\n","\n","1. Final prompt: The final prompt that is returned\n","\n","2. Pipeline prompts: A list of tuples, consisting of a string name and a prompt template. Each prompt template will be formatted and then passed to future prompt templates as a variable with the same name."],"metadata":{"id":"rl5mldDcqzOp"}},{"cell_type":"code","source":["from langchain.prompts.pipeline import PipelinePromptTemplate\n","from langchain.prompts.prompt import PromptTemplate"],"metadata":{"id":"328V_Y-Qq1UH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_template = \"\"\"{introduction}\n","\n","{example}\n","\n","{start}\"\"\"\n","\n","full_prompt = PromptTemplate.from_template(full_template)"],"metadata":{"id":"4IUN1EfirhVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["introduction_template = \"\"\"You are impersonating {person}.\"\"\"\n","introduction_prompt = PromptTemplate.from_template(introduction_template)"],"metadata":{"id":"j2w6SdMmnXDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_template = \"\"\"Here's an example of an interaction:\n","\n","Q: {example_q}\n","A: {example_a}\"\"\"\n","example_prompt = PromptTemplate.from_template(example_template)"],"metadata":{"id":"3JbuG8wEnYe9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_template = \"\"\"Now, do this for real!\n","\n","Q: {input}\n","A:\"\"\"\n","start_prompt = PromptTemplate.from_template(start_template)"],"metadata":{"id":"pHAMVyaGnZ9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_prompts = [\n","    (\"introduction\", introduction_prompt),\n","    (\"example\", example_prompt),\n","    (\"start\", start_prompt)\n","]\n","pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"],"metadata":{"id":"Drwq7Z4cnbN7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipeline_prompt.input_variables"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYgcG7BAncnT","executionInfo":{"status":"ok","timestamp":1696505666643,"user_tz":300,"elapsed":97,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"3b0cd90f-df93-485d-8c39-a7e77e94b1de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['person', 'input', 'example_q', 'example_a']"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["last_prompt = pipeline_prompt.format(\n","    person=\"Elon Musk\",\n","    example_q=\"What's your favorite car?\",\n","    example_a=\"Tesla\",\n","    input=\"What's your favorite social media site?\"\n",")\n","\n","print(last_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsNGuKCXnhpz","executionInfo":{"status":"ok","timestamp":1696505987638,"user_tz":300,"elapsed":2,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"21514d19-dd17-44ae-bb56-d94757aa3a41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["You are impersonating Elon Musk.\n","\n","Here's an example of an interaction: \n","\n","Q: What's your favorite car?\n","A: Tesla\n","\n","Now, do this for real!\n","\n","Q: What's your favorite social media site?\n","A:\n"]}]},{"cell_type":"code","source":["from langchain.llms import OpenAI\n","\n","llm=OpenAI()\n","\n","llm(last_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ahbbsNgSoUtw","executionInfo":{"status":"ok","timestamp":1696506021330,"user_tz":300,"elapsed":202,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"dd4d7ddb-c97a-4846-becc-c5a983253ded"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Twitter!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n","\n","class CookingShowChatbot:\n","    def __init__(self):\n","        # Base template for the cooking show scenario\n","        self.full_template = \"\"\"{introduction}\n","        {example_dish}\n","\n","        {present_dish}\"\"\"\n","        self.full_prompt = PromptTemplate.from_template(self.full_template)\n","\n","        # Introduction where the user impersonates a famous chef\n","        self.introduction_template = \"\"\"Welcome to the cooking show! Today, you're channeling the spirit of Chef {chef_name}.\"\"\"\n","        self.introduction_prompt = PromptTemplate.from_template(self.introduction_template)\n","\n","        # Example dish made by the famous chef\n","        self.example_dish_template = \"\"\"Remember when Chef {chef_name} made that delicious {example_dish_name}? It was a hit!\"\"\"\n","        self.example_dish_prompt = PromptTemplate.from_template(self.example_dish_template)\n","\n","        # User's turn to present their dish\n","        self.present_dish_template = \"\"\"Now, it's your turn! Show us how you make your {user_dish_name}. Let's get cooking!\"\"\"\n","        self.present_dish_prompt = PromptTemplate.from_template(self.present_dish_template)\n","\n","        # Combining the prompts into a pipeline\n","        self.input_prompts = [\n","            (\"introduction\", self.introduction_prompt),\n","            (\"example_dish\", self.example_dish_prompt),\n","            (\"present_dish\", self.present_dish_prompt)\n","        ]\n","        self.pipeline_prompt = PipelinePromptTemplate(final_prompt=self.full_prompt,\n","                                                      pipeline_prompts=self.input_prompts\n","                                                      )\n","\n","    def run_scenario(self, chef_name, example_dish_name, user_dish_name):\n","        return self.pipeline_prompt.format(\n","            chef_name=chef_name,\n","            example_dish_name=example_dish_name,\n","            user_dish_name=user_dish_name\n","        )\n","\n","# Usage\n","chatbot = CookingShowChatbot()\n","scenario = chatbot.run_scenario(chef_name=\"Gordon Ramsay\", example_dish_name=\"Beef Wellington\", user_dish_name=\"Vegan Lasagna\")\n","print(scenario)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFIiHk-FnjVu","executionInfo":{"status":"ok","timestamp":1696505863891,"user_tz":300,"elapsed":119,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"026f5070-93f7-416e-bbe8-8867da553134"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome to the cooking show! Today, you're channeling the spirit of Chef Gordon Ramsay.\n","        Remember when Chef Gordon Ramsay made that delicious Beef Wellington? It was a hit!\n","        \n","        Now, it's your turn! Show us how you make your Vegan Lasagna. Let's get cooking!\n"]}]},{"cell_type":"code","source":["print(llm(scenario))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjGCHwc1oRz9","executionInfo":{"status":"ok","timestamp":1696506054063,"user_tz":300,"elapsed":4269,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"db57ca8f-cd12-4ed6-ddf0-86a5c3671eeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Step 1: Preheat oven to 375°F.\n","\n","Step 2: Begin by preparing the vegan ricotta cheese. In a food processor, combine 2 containers of extra firm tofu, 2 tablespoons of olive oil, 2 cloves of garlic, 2 tablespoons of nutritional yeast, 1 teaspoon of salt, 1 teaspoon of dried oregano, and 1 teaspoon of dried basil. Blend until creamy and set aside.\n","\n","Step 3: In a large saucepan, heat 2 tablespoons of olive oil over medium-high heat and add 1 diced onion. Cook for 3 minutes, stirring occasionally.\n","\n","Step 4: Add 3 cloves of minced garlic and cook for 1 minute.\n","\n","Step 5: Add 2 cans of crushed tomatoes and 1 teaspoon of salt. Bring to a simmer and cook for 10 minutes, stirring occasionally.\n","\n","Step 6: In a 9x13 inch baking dish, spread 1 cup of the tomato sauce evenly over the bottom.\n","\n","Step 7: Layer 4 uncooked lasagna noodles on top of the sauce.\n","\n","Step 8: Spread half of the vegan ricotta cheese over the noodles, followed by 1 cup of the tomato sauce.\n","\n","Step 9: Add 4 more noodles and spread the remaining vegan ricotta cheese on top\n"]}]}]}