{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_KoR5Az87Sg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install openai langchain faiss-cpu tiktoken unstructured"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Whats the OpenAI Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r39Zna_99HUK",
        "outputId": "9fc9c360-1878-4cbf-8d67-7ec70516ae85"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whats the OpenAI Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.document_loaders import UnstructuredHTMLLoader\n",
        "from langchain.document_loaders import BSHTMLLoader"
      ],
      "metadata": {
        "id": "RoW5CyK_9O9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_paths = [\n",
        "    \"https://www.unite.ai/the-future-of-generative-ai-is-the-edge/\",\n",
        "    \"https://venturebeat.com/ai/how-businesses-can-achieve-greener-generative-ai-with-more-sustainable-inference/\",\n",
        "    \"https://semiengineering.com/generative-ai-transforming-inference-at-the-edge/\"\n",
        "]"
      ],
      "metadata": {
        "id": "N1HG2ylBEjRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(web_paths=web_paths).load()"
      ],
      "metadata": {
        "id": "Us1c4up_FcIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "NDYUodAQHp4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap = 10,\n",
        "    length_function = len\n",
        ")"
      ],
      "metadata": {
        "id": "dJgQgXYTISKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_docs = text_splitter.split_documents(loader)"
      ],
      "metadata": {
        "id": "8np_iV8THp7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Filter out documents with more than 4 consecutive newline characters in page_content\n",
        "filtered_texts = [document for document in split_docs if not re.search('\\n{5,}', document.page_content)]"
      ],
      "metadata": {
        "id": "Kou37tcUJiAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "Ik7mcEfMJ04_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "MgBv1MtXKHnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "zNpfAI23Ki_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = FAISS.from_documents(\n",
        "    documents = filtered_texts,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        ")"
      ],
      "metadata": {
        "id": "46TYQBWVKBod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "Vfmh7fKcKZZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "PRzh1w3nKbdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=retriever)"
      ],
      "metadata": {
        "id": "wWBUqNAJKs1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(\"What challenges does Gen AI at the edge face?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "_Am2frpnK2eL",
        "outputId": "5e5fc713-b4bd-455f-e00c-e0c95c6377ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Gen AI at the edge faces several challenges, including:\\n\\n1. Limited processing power: Edge devices typically have limited computational capabilities compared to cloud servers or data centers. This can pose a challenge in running complex generative AI models that require significant computing resources.\\n\\n2. Storage limitations: Edge devices often have limited storage capacity, which can restrict the size and complexity of generative AI models that can be deployed on them.\\n\\n3. Network connectivity: Edge devices may have limited or intermittent network connectivity, which can affect their ability to access cloud-based resources or receive updates for generative AI models.\\n\\n4. Energy consumption: Running generative AI models on edge devices can consume significant amounts of power, which can impact battery life for portable devices and increase energy costs for larger deployments.\\n\\n5. Model customization: Generative AI models deployed at the edge may need to be customized for specific use cases or domains. This customization process can be challenging and require expertise in machine learning and AI.\\n\\n6. Security and privacy: Edge devices may be more vulnerable to security threats compared to cloud servers. Protecting the privacy of sensitive data processed by generative AI models at the edge is also crucial.\\n\\nAddressing these challenges is necessary to ensure the successful deployment and operation of generative AI at the edge.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gen AI at the edge faces several challenges, including:\n",
        "\n",
        "1. Limited processing power: Edge devices typically have limited computational capabilities compared to cloud servers or data centers. This can pose a challenge in running complex generative AI models that require significant computing resources.\n",
        "\n",
        "2. Storage limitations: Edge devices often have limited storage capacity, which can restrict the size and complexity of generative AI models that can be deployed on them.\n",
        "\n",
        "3. Network connectivity: Edge devices may have limited or intermittent network connectivity, which can affect their ability to access cloud-based resources or receive updates for generative AI models.\n",
        "\n",
        "4. Energy consumption: Running generative AI models on edge devices can consume significant amounts of power, which can impact battery life for portable devices and increase energy costs for larger deployments.\n",
        "\n",
        "5. Model customization: Generative AI models deployed at the edge may need to be customized for specific use cases or domains. This customization process can be challenging and require expertise in machine learning and AI.\n",
        "\n",
        "6. Security and privacy: Edge devices may be more vulnerable to security threats compared to cloud servers. Protecting the privacy of sensitive data processed by generative AI models at the edge is also crucial.\n",
        "\n",
        "Addressing these challenges is necessary to ensure the successful deployment and operation of generative AI at the edge."
      ],
      "metadata": {
        "id": "owOhvJ6qK9ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain"
      ],
      "metadata": {
        "id": "MRpa0U-bLJOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RetrievalQAWithSourcesChain.from_chain_type?"
      ],
      "metadata": {
        "id": "KL9Lfn3NLRZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI()\n",
        "qa_source_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        "    )"
      ],
      "metadata": {
        "id": "hlPXCDRILMey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_source_chain.invoke(\"What challenges does Gen AI at the edge face?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hW1Z1mNL3I1",
        "outputId": "1c50e326-4f3b-4560-b994-3f7633dbd0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What challenges does Gen AI at the edge face?',\n",
              " 'answer': 'Gen AI at the edge faces challenges such as latency, privacy, security, scalability, compute cost, and energy consumption. These challenges can be addressed by moving AI compute workloads to the edge, utilizing processing solutions optimized for AI workloads. This approach provides benefits such as lower latency, improved privacy and reliability, and increased capability. Moving Gen AI to the edge is seen as the future and present for enterprise-specific applications. \\n',\n",
              " 'sources': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    }
  ]
}