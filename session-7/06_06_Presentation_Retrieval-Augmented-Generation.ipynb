{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FCz0cvWF_wbA"},"outputs":[],"source":["%%capture\n","!pip install langchain openai\n","!pip install -q -U faiss-cpu tiktoken"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gnISdj8lMqKr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694193478014,"user_tz":300,"elapsed":3351,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"}},"outputId":"0f39cb03-a097-4567-ff0c-5a8f11dc0b71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Open AI API Key:··········\n"]}],"source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Open AI API Key:\")"]},{"cell_type":"markdown","metadata":{"id":"CiCAlO7L-VlD"},"source":["# Retrieval Augmented Generation (RAG)\n","\n","[Meta AI introduced the RAG method](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/), emphasizing its potential for knowledge-intensive tasks.\n","\n","## 🔍 **1. What is RAG?**\n","\n","- 🤖 RAG, or Retrieval Augmented Generation, boosts large language models (LLMs) by tapping into external knowledge sources.\n","\n","- 🚀 Meta AI pioneered RAG to tackle knowledge-heavy tasks efficiently.\n","\n","- 💡 Combines info retrieval with text generation, enabling LLMs to access fresh, reliable info.\n","\n","- 🎯 Ideal for tasks needing accurate, current data.\n","\n","## 🤔 **2. Why RAG was developed?**\n","\n","- 📝 LLMs excel in mimicking human text but face limitations.\n","\n","- 💸 High training/fine-tuning costs.\n","\n","- 📚 Knowledge is static, outdated post-training.\n","\n","- 🌌 \"Hallucinating\" issue: confidently giving wrong info.\n","\n","- 🌐 RAG overcomes these by merging LLM prowess with real-time data access.\n","\n","## 3. 🛠️ **3. How RAG Works?**\n","\n","- 🔎 **Retrieval Component:** On receiving a query (like a question), RAG fetches relvant documents/passages from external sources (like Wikipedia).\n","\n","- ✍️ **Generation Component:** Blends these retrieved docs with the query to create an enriched context. This is then processed by a text generator (e.g., GPT-3) to generate the final answer.\n","\n","<img src=\"https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/jumpstart/jumpstart-fm-rag.jpg\">\n","\n","## 🌟 **4. Key Features of RAG:**\n","\n","- 🔄 **Dynamic Knowledge Access:** RAG stays current, accessing the latest info, unlike static-knowledge LLMs.\n","\n","- 💸 **Cost Efficiency:** Integrates fresh info without the high cost of retraining the whole LLM.\n","\n","- ✔️ **Accuracy and Reliability:** Sources reliable info, reducing wrong answers or \"hallucinations.\"\n","\n","## 🛠 **5. Practical Implementations:**\n","\n","- ❓ Answering evolving topic questions.\n","\n","- 🔬 Useful in domains needing real-time accuracy (e.g., medical, legal).\n","\n","- 🤖 Boosts chatbots/virtual assistants with factual, updated replies.\n","\n","## 📌 **In Summary:**\n","\n","- RAG: Marrying vast LLM knowledge with the latest real-world info.\n","\n","- Ensures models are not just knowledgeable, but also up-to-date and accurate.\n","\n","# 🛠️ **RAG Implementation in LangChain: Understanding the Tools**\n","\n","1. 🧠 **LLM**: The brain of the system, generating human-like text.\n","\n","2. 🌐 **Vector Store**: The heart of retrieval - stores text embeddings for quick, efficient access.\n","\n","3. 🔍 **Vector Store Retriever**: The system's \"search engine,\" finding relevant documents via vector similarities.\n","\n","4. 🔄 **Embedder**: Transforms text into vectors, making it readable for the system.\n","\n","5. 💬 **Prompt**: Captures the initial user query or statement, kicking off the process.\n","\n","6. 📚 **Document Loader**: Manages the import and preparation of documents for processing.\n","\n","7. 🧩 **Document Chunker**: Breaks down large documents into smaller segments for better efficiency.\n","\n","8. 👤 **User Input**: The starting point, where the user's query activates the RAG workflow.\n","\n","\n","# 🌐 **The RAG System and Its Subsystems**\n","\n","1. 🗂️ **Index Subsystem**:\n","   - **Components**: Embedder, Vector Store, Document Loader, Document Chunker.\n","   - **Function**: Processes and organizes data into an accessible format.\n","   - **Role**: Creates a searchable database of vectorized information.\n","\n","2. 🔎 **Retrieval Subsystem**:\n","   - **Components**: User Input, Prompt, Vector Store Retriever.\n","   - **Function**: Matches user queries with relevant data.\n","   - **Role**: Fetches the most pertinent information from the index based on user input.\n","\n","3. 🤖 **Augment Subsystem**:\n","   - **Components**: LLM, User Input, Retrieved Data.\n","   - **Function**: Integrates user queries with retrieved data.\n","   - **Role**: Generates accurate and context-rich responses, blending human-like text generation with factually correct information.\n","\n","Together, these subsystems form a seamless flow, transforming user queries into comprehensive and reliable responses."]},{"cell_type":"markdown","metadata":{"id":"iK3gf7TDH9GS"},"source":["# Load documents\n","There are SO MANY document loaders in LangChain\n","\n","I won't go every single one in this notebook. But, you can check out [the documentation](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/document_loaders) to see jusy how many are available to you.\n","\n","## 📂 **Understanding Document Loaders in LangChain**\n","\n","- 📚 LangChain document loaders load data from various sources into Document objects.\n","\n","- 📄 A Document is text with metadata.\n","\n","- 🌐 Loaders fetch data from text files, web pages, video transcripts, etc.\n","\n","- 🔄 Main role: Retrieve data for further processing.\n","\n","- 🛠️ Method: Use `load` to fetch data and return it as a Document.\n","\n","- 🧠 Some loaders support lazy loading (data loads into memory only when needed).\n","\n","## 🔧 **How to Use Document Loaders**\n","\n","1. 📥 Import the loader class from `langchain.document_loaders`.\n","\n","2. 🏗️ Create an instance of your chosen class with the directory path.\n","\n","3. 🚀 Use `load()` to load files in the directory into Document format.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmKgqy5X_vhA"},"outputs":[],"source":["from langchain.document_loaders import WebBaseLoader\n","\n","yolo_nas_loader = WebBaseLoader(\"https://deci.ai/blog/yolo-nas-object-detection-foundation-model/\").load()\n","\n","decicoder_loader = WebBaseLoader(\"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llmx\").load()\n","\n","yolo_newsletter_loader = WebBaseLoader(\"https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas\").load()"]},{"cell_type":"markdown","metadata":{"id":"H1shOpId_vqb"},"source":["# Chunk documents\n","\n","🔢 **Exploring Text Splitters in LangChain**\n","\n","- 📖 Text splitters divide long texts into\n","smaller, meaningful parts.\n","\n","- 🧩 Aim: Make large texts easier to handle for analysis or processing.\n","\n","### How Text Splitters Work:\n","\n","1. ✂️ Split text into small, meaningful chunks (like sentences).\n","\n","2. 📏 Combine these chunks into a larger one until a certain size is reached.\n","\n","3. 📌 Once the size is reached, start a new chunk with some overlap for context.\n","\n","### Customization Axes:\n","\n","1. 🛠️ How the text is split.\n","\n","2. 📐 How chunk size is measured.\n","\n","## Getting Started with Text Splitters\n","\n","- 🚀 Default choice: `RecursiveCharacterTextSplitter`.\n","\n","- 📋 Works by: Splitting text based on a list of characters.\n","\n","- 🔄 If chunks are too large, it moves to the next character.\n","\n","- 📌 Default split characters: `[\"\\n\\n\", \"\\n\", \" \", \"\"]`.\n","\n","### Additional Controls:\n","\n","- 📏 `length_function`: Defines how chunk length is calculated (default: character count, token counter is common).\n","\n","- 🔍 `chunk_size`: Sets the maximum chunk size.\n","\n","- 🔀 `chunk_overlap`: Determines overlap between chunks for continuity.\n","\n","- 📊 `add_start_index`: Option to include each chunk's start position in the original document in metadata."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuXm06J1IDs7"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 500,\n","    chunk_overlap = 50,\n","    length_function = len\n",")\n","\n","yolo_nas_chunks = text_splitter.transform_documents(yolo_nas_loader)\n","\n","decicoder_chunks = text_splitter.transform_documents(decicoder_loader)\n","\n","yolo_newsletter_chunks = text_splitter.transform_documents(yolo_newsletter_loader)"]},{"cell_type":"markdown","metadata":{"id":"cGzRpURwJqHM"},"source":["# Index System\n","\n","- 🎯 **Purpose:** Efficiently organize data for easy retrieval.\n","\n","### Steps in the Index System:\n","1. 📚 **Load Documents (Document Loader):**\n","   - Import and read large amounts of data.\n","2. 🧩 **Chunk Documents (Document Chunker):**\n","   - Break down documents into smaller parts for better handling.\n","3. 🌐 **Embed Documents (Embedder):**\n","   - Convert text chunks into vector formats for searchability.\n","4. 💾 **Store Embeddings (Vector Store):**\n","   - Keep embeddings and their textual counterparts for retrieval."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGtfN_hiJzVB"},"outputs":[],"source":["from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.embeddings import CacheBackedEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.storage import LocalFileStore\n","\n","store = LocalFileStore(\"./cachce/\")\n","\n","# create an embedder\n","core_embeddings_model = OpenAIEmbeddings()\n","\n","embedder = CacheBackedEmbeddings.from_bytes_store(\n","    core_embeddings_model,\n","    store,\n","    namespace = core_embeddings_model.model\n",")\n","\n","# store embeddings in vector store\n","vectorstore = FAISS.from_documents(yolo_nas_chunks, embedder)\n","\n","vectorstore.add_documents(decicoder_chunks)\n","\n","vectorstore.add_documents(yolo_newsletter_chunks)\n","\n","# instantiate a retriever\n","retriever = vectorstore.as_retriever()"]},{"cell_type":"markdown","metadata":{"id":"r4HNkh6pmQ61"},"source":["# 🔍 **Understanding the Retrieval System in Information Access**\n","\n","- 🎯 **Purpose:** Fetch relevant information based on user queries.\n","\n","### Steps in the Retrieval System:\n","\n","1. 💬 **Obtain User Query (User Input):**\n","   - Capture the user's question or statement.\n","\n","2. 🔄 **Embed User Query (Embedder):**\n","   - Convert the user's query into a vector format, aligning with indexed documents.\n","\n","3. 🔍 **Vector Search (Vector Store Retriever):**\n","   - Search for document embeddings in the Vector Store that closely match the user query.\n","\n","4. 📄 **Return Relevant Documents:**\n","   - Provide the top matching documents, ensuring pertinence to the query."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eq3nKNJ2mRDK"},"outputs":[],"source":["from langchain.llms.openai import OpenAIChat\n","from langchain.chains import RetrievalQA\n","from langchain.callbacks import StdOutCallbackHandler"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1694194732261,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"D9FGhpMWORwa","outputId":"a020b3ca-68fb-4fc2-a8aa-5ce4c881f2f3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:787: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n","  warnings.warn(\n"]}],"source":["llm = OpenAIChat()\n","handler =  StdOutCallbackHandler()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBhaA_nkpU_2"},"outputs":[],"source":["# this is the entire retrieval system\n","qa_with_sources_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    retriever=retriever,\n","    callbacks=[handler],\n","    return_source_documents=True,\n","    verbose=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"ZAaIa-kpsHHI"},"source":["# Augment System\n","\n","- 🎯 **Purpose:** Improve the LLM input prompt with relevant context for better responses.\n","\n","### Steps in the Augment System:\n","1. 📝 **Create Initial Prompt (Prompt):**\n","   - Begin with the user's original query or statement.\n","2. ✨ **Augment Prompt with Retrieved Context:**\n","   - Combine the initial prompt with context from the Vector Store for a richer input.\n","3. 📤 **Send Augmented Prompt to LLM:**\n","   - Forward the enhanced prompt to the LLM for processing.\n","4. 📥 **Receive LLM's Response:**\n","   - Get the comprehensive response generated by the LLM."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3028,"status":"ok","timestamp":1694194778148,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"Q-NO6i0YS6nY","outputId":"1471855a-4155-4e86-ace9-70a9c1a7596c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}],"source":["# This is the entire augment system!\n","response = qa_with_sources_chain({\"query\":\"What does Neural Architecture Search have to do with how Deci creates its models?\"})"]},{"cell_type":"markdown","metadata":{"id":"9vTXxxh0xBl0"},"source":["Look at the entire response  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1694194783386,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"jGBkR1ewxHWY","outputId":"780c8083-3f53-4fd7-adb7-70280d8bafae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'query': 'What does Neural Architecture Search have to do with how Deci creates its models?',\n"," 'result': 'Deci uses Neural Architecture Search (NAS) technology, specifically AutoNAC, to create efficient and effective neural network architectures for its models. AutoNAC intelligently searches a large space of possible architectures and zeroes in on the most promising ones. This technology allows Deci to automate the development of superior neural networks and optimize the accuracy and speed of its models.',\n"," 'source_documents': [Document(page_content='Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With the architecture and training regime in place, our researchers harnessed the power of AutoNAC. It intelligently searched a vast space of ~10^14 possible architectures, ultimately zeroing in on three final networks that promised outstanding results. The result is a family of architectures with a novel quantization-friendly basic', metadata={'source': 'https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas', 'title': 'Unleashing the Power of YOLO-NAS: A New Era in Object Detection and Computer Vision', 'description': 'The Future of Computer Vision is Here', 'language': 'en'}),\n","  Document(page_content='Deci’s suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder’s efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder’s architecture were generated using Deci’s proprietary Neural Architecture Search technology, AutoNAC™.\\xa0\\nAnother Win for AutoNAC', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n","  Document(page_content='The quest for the “optimal” neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n","  Document(page_content='This new model is fast and accurate, offering the best accuracy-latency tradeoff among existing object detection models on the market. This accomplishment was made possible by Deci’s AutoNAC neural architecture search technology, which efficiently constructs deep learning models for any task and hardware.', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'})]}"]},"metadata":{},"execution_count":13}],"source":["response"]},{"cell_type":"markdown","source":["If you want just the response"],"metadata":{"id":"2kYiibKxzENe"}},{"cell_type":"code","source":["print(response['result'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x1JOCbQZzC0R","executionInfo":{"status":"ok","timestamp":1693253980322,"user_tz":300,"elapsed":280,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"}},"outputId":"3af839e0-4c74-4e8d-dc43-d78e61cfc034"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Deci utilizes Neural Architecture Search (NAS) technology, specifically their proprietary AutoNAC technology, to automatically generate and optimize the architecture of their models. Neural Architecture Search helps Deci in efficiently constructing deep learning models for various tasks and hardware.\n"]}]},{"cell_type":"markdown","source":["And you can get the source like so:"],"metadata":{"id":"agbQB4A_zZrm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1693253955216,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"mV8rFTyST_nD","outputId":"af675b72-ef5e-44ff-b051-547a8626468e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Document(page_content='Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With the architecture and training regime in place, our researchers harnessed the power of AutoNAC. It intelligently searched a vast space of ~10^14 possible architectures, ultimately zeroing in on three final networks that promised outstanding results. The result is a family of architectures with a novel quantization-friendly basic', metadata={'source': 'https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas', 'title': 'Unleashing the Power of YOLO-NAS: A New Era in Object Detection and Computer Vision', 'description': 'The Future of Computer Vision is Here', 'language': 'en'}), Document(page_content='Deci’s suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder’s efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder’s architecture were generated using Deci’s proprietary Neural Architecture Search technology, AutoNAC™.\\xa0\\nAnother Win for AutoNAC', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}), Document(page_content='The quest for the “optimal” neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}), Document(page_content='This new model is fast and accurate, offering the best accuracy-latency tradeoff among existing object detection models on the market. This accomplishment was made possible by Deci’s AutoNAC neural architecture search technology, which efficiently constructs deep learning models for any task and hardware.', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'})]\n"]}],"source":["print(response['source_documents'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2442,"status":"ok","timestamp":1693252837146,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"0-3BqcQJTBu2","outputId":"203856f7-7897-48cc-ad6c-e4330c24b736"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}],"source":["response = qa_with_sources_chain({\"query\":\"What is DeciCoder\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693252841122,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"PbsKa0nKu-XP","outputId":"1bddf350-2c2f-4956-bec5-c52f6d62b902"},"outputs":[{"name":"stdout","output_type":"stream","text":["DeciCoder is a 1B-parameter open-source Large Language Model (LLM) for code generation. It has a 2048-context window, permissively licensed, delivers a 3.5x increase in throughput, improved accuracy on the HumanEval benchmark, and smaller memory usage compared to widely-used code generation LLMs such as SantaCoder.\n"]}],"source":["print(response['result'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8033,"status":"ok","timestamp":1693252877008,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"6RwqP62Uu9Tc","outputId":"2923f8be-c722-4556-a750-cf6be2c837d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}],"source":["response = qa_with_sources_chain({\"query\":\"Write a blog about Deci and how it used NAS to generate YOLO-NAS and DeciCoder\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1693252878902,"user":{"displayName":"Harpreet Sahota","userId":"15663196278719964515"},"user_tz":300},"id":"qivMMWHMvFqe","outputId":"473a160b-a0c7-4531-b1c5-40b89c611627"},"outputs":[{"name":"stdout","output_type":"stream","text":["Deci, a company focused on pushing the boundaries of accuracy and efficiency, has introduced a new architecture called YOLO-NAS. YOLO-NAS is a benchmark for object detection that has the potential to drive innovation and unlock new possibilities across various industries and research domains.\n","\n","Deci has showcased its robust capabilities with the DeciCoder model, which consistently outperforms models like SantaCoder. By leveraging AutoNAC, Deci was able to generate an architecture that is both efficient and powerful.\n","\n","Deci's use of NAS (Neural Architecture Search) played a pivotal role in the development of YOLO-NAS. NAS is a technique that automates the design process of neural networks, allowing for the discovery of optimized architectures. By deploying NAS, Deci was able to achieve state-of-the-art performance on object detection with YOLO-NAS.\n","\n","The integration of NAS in the development of YOLO-NAS and DeciCoder showcases Deci's commitment to pushing the boundaries of AI innovation. With the YOLO-NAS architecture and DeciCoder, Deci aims to provide advanced solutions for various use cases, such as running on edge devices, optimizing generative AI models, reducing cloud costs, shortening development time, and maximizing data center utilization.\n","\n","Deci's focus on accuracy, efficiency, and innovation through the use of NAS sets them apart in the industry. Their dedication to driving progress in object detection and AI research makes them a valuable player in the field.\n"]}],"source":["print(response['result'])"]}],"metadata":{"colab":{"provenance":[{"file_id":"1XfUn-YcMT1gAC4K6qUlkKiEubj0Tj0Pu","timestamp":1697209253839},{"file_id":"14VRXcGHu6u0R15AE8cjefERSgdszBYmW","timestamp":1697207548768}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}