{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP97m2LeQR4OJPN7Rw2aBR1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7069787a8a2b404aad0fd1267c9fd3fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffdcedfbb2a64d5fbbdefab0fa0ab9d7","IPY_MODEL_a2851fe08ef34d9297e803b57e08637e","IPY_MODEL_3f659e7aef2e41c6888558703a55a6aa"],"layout":"IPY_MODEL_eb0158790f0b42a6aad80b86bf7664fc"}},"ffdcedfbb2a64d5fbbdefab0fa0ab9d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0814a2744ce948e5805e68638c6a071a","placeholder":"‚Äã","style":"IPY_MODEL_86b4240ff7814418bfa306e1ee27f4c6","value":"Loading checkpoint shards: 100%"}},"a2851fe08ef34d9297e803b57e08637e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5d2e69ab92e4b8a996497a4824f2232","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d576fddff3dd4ff9b04660e34618444d","value":3}},"3f659e7aef2e41c6888558703a55a6aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30da75e6f5894c73bba53a865cf0ea90","placeholder":"‚Äã","style":"IPY_MODEL_c8331d08c092492193e2d5dc57a0b47d","value":" 3/3 [00:41&lt;00:00, 21.52s/it]"}},"eb0158790f0b42a6aad80b86bf7664fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0814a2744ce948e5805e68638c6a071a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86b4240ff7814418bfa306e1ee27f4c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5d2e69ab92e4b8a996497a4824f2232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d576fddff3dd4ff9b04660e34618444d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30da75e6f5894c73bba53a865cf0ea90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8331d08c092492193e2d5dc57a0b47d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tDvlR1TtenPm"},"outputs":[],"source":["%%capture\n","!pip install langchain openai cohere huggingface_hub transformers accelerate"]},{"cell_type":"code","source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mu0HhEGOfKTO","executionInfo":{"status":"ok","timestamp":1695900718301,"user_tz":300,"elapsed":22434,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"e09e8052-9126-4866-9ce0-205c6216d4f8"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Your OpenAI API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXBdCPPqfLVC","executionInfo":{"status":"ok","timestamp":1695900726329,"user_tz":300,"elapsed":7753,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"5ba52da7-4368-48fa-98c3-903a0b4d5906"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Cohere API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"HF API Key:\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fT16wllYhwjo","executionInfo":{"status":"ok","timestamp":1695900733629,"user_tz":300,"elapsed":5222,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"a4aa9840-7eb5-44f0-99b0-8f6ec89009d4"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["HF API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"markdown","source":["# Model I/O\n","\n","There are three components to this module:\n","\n","  1) Prompts, which provide templates that allow you to parametrize and reuse prompts.\n","\n","  2) Language models, which allow you to interface with:\n","\n","  ‚Ä¢ LLMs, which take a string as input and return a string as output\n","  \n","  ‚Ä¢ Chat models, which take a list of chat messages as input and return\n","\n","  3) Output Parsers allow you to extract and structure the text output from a language model in the way you want. These are useful for tasks like QA, where you must parse an answer.\n","\n","The typical workflow is as follows:\n","\n","‚Ä¢ Choose either an LLM or a Chat model; this depends on your use case\n","\n","‚Ä¢ Construct a prompt that you customize as the inputs\n","\n","‚Ä¢ Send the input to the LLM or Chat model\n","\n","‚Ä¢ Parse outputs with output parsers, if needed\n","\n","## üñ±Ô∏è Let's double-click on the language models component.  \n","\n","In general, all Chat models are LLMs. But, not all LLMs are Chat models.\n","\n","But both implement the same Base Language Model interface, making it easy to swap between them.\n","\n","### üó£Ô∏è LLMs:\n","\n","‚Ä¢ Take a string as input and return a string as output\n","\n","‚Ä¢ Implemented for models optimized for text completion\n","\n","‚Ä¢ Expose a `predict` method that takes a string prompt and returns a string completion\n","\n","### üí¨ Chat models:\n","\n","‚Ä¢ Take a list of `ChatMessages` as input and return a `ChatMessage` as output\n","\n","‚Ä¢ Implemented for models that are tuned for dialogue\n","\n","‚Ä¢ Expose a `predict_messages` method that takes a list of ChatMessages and returns a single ChatMessage\n","\n","‚Ä¢ ChatMessages contain a content field with the message text and a role field indicating the speaker\n","\n","### üîë The key differences:\n","‚Ä¢ Input/output types: strings vs. ChatMessages\n","\n","‚Ä¢ Methods: `predict` vs. `predict_messages`\n","\n","‚Ä¢ Optimization: text completion vs. dialog\n","\n","# Working LLMs\n","\n","The LLM class is designed to be a standard interface to an LLM provider. This class abstracts away provider-specific APIs and exposes common methods like `predict` and `generate`.\n","\n","‚Ä¢ `predict` is optimized for text completion. It allows you to format a prompt template and pass it to the language model. The output is just plain text.\n","\n","‚Ä¢ `generate` takes a list of prompts and returns detailed `LLMResult` objects with completions and metadata.\n","\n","Let's instantiate LLMs from Cohere, OpenAI, and HuggingFace and take a look at the difference between the generate and predict method.\n","\n","## Predict method\n","\n","Notice that it's the same API for each of the different models, which is nice.\n"],"metadata":{"id":"Cq9meZFkgSWg"}},{"cell_type":"code","source":["from langchain.llms import OpenAI, Cohere, HuggingFacePipeline, HuggingFaceHub\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","import transformers\n","import torch\n","\n","openai_llm = OpenAI()\n","\n","cohere_llm = Cohere()\n","\n","model_id = 'Deci/DeciLM-6b-instruct'\n","\n","task = \"text-generation\"\n","\n","model = AutoModelForCausalLM.from_pretrained(model_id,\n","                                             device_map=\"auto\",\n","                                             trust_remote_code=True\n","                                             )\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","pipe = pipeline(\n","    task,\n","    model=model,\n","    tokenizer=tokenizer,\n","    temperature=0,\n","    max_new_tokens=512,\n","    num_beams=1,\n","    early_stopping=True,\n","    num_return_sequences=1,\n","    eos_token_id=tokenizer.eos_token_id\n",")\n","\n","huggingface_llm = HuggingFacePipeline(pipeline=pipe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["7069787a8a2b404aad0fd1267c9fd3fc","ffdcedfbb2a64d5fbbdefab0fa0ab9d7","a2851fe08ef34d9297e803b57e08637e","3f659e7aef2e41c6888558703a55a6aa","eb0158790f0b42a6aad80b86bf7664fc","0814a2744ce948e5805e68638c6a071a","86b4240ff7814418bfa306e1ee27f4c6","e5d2e69ab92e4b8a996497a4824f2232","d576fddff3dd4ff9b04660e34618444d","30da75e6f5894c73bba53a865cf0ea90","c8331d08c092492193e2d5dc57a0b47d"]},"id":"xwXxRL1IhAjU","executionInfo":{"status":"ok","timestamp":1695902077345,"user_tz":300,"elapsed":43409,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"dd713b1e-af1c-4388-ebf5-6d59cbb825eb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7069787a8a2b404aad0fd1267c9fd3fc"}},"metadata":{}}]},{"cell_type":"code","source":["prompt = \"How do I become an AI Engineer?\""],"metadata":{"id":"C-EXtNczmubN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["openai_llm.predict(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"FVRTxwyYiemG","executionInfo":{"status":"ok","timestamp":1695900742351,"user_tz":300,"elapsed":4239,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"7c5165c0-8fdd-439d-b1a0-be63823d2694"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n\\n1. Earn a bachelor's degree in computer science or a related field. Most AI engineers possess a degree in computer science, software engineering, or a related field.\\n\\n2. Develop a strong background in mathematics and programming. AI engineering requires an extensive knowledge of mathematics and programming languages such as Python and Java.\\n\\n3. Gain experience with AI technologies. AI engineers must be familiar with AI technologies such as machine learning, natural language processing, and robotics. You should also become familiar with AI frameworks such as TensorFlow and Apache Spark.\\n\\n4. Build a portfolio. You should create a portfolio of projects that demonstrate your skills in AI engineering.\\n\\n5. Consider certification. You may consider obtaining an AI certification to demonstrate your knowledge and skills.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["cohere_llm.predict(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"O1-_aBEpieys","executionInfo":{"status":"ok","timestamp":1695900748943,"user_tz":300,"elapsed":6596,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"6f3d08e7-f96b-4b70-a8e6-622c2ae938fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" There is no single path to becoming an AI engineer, but there are several steps you can take to get started in the field. First, it is important to have a strong foundation in computer science and mathematics, as these are the building blocks of AI. You should also be familiar with programming languages such as Python, R, and Java, as well as data structures and algorithms. \\n\\nIn addition, it is helpful to have experience with machine learning algorithms and deep learning frameworks. You should also be familiar with data structures and algorithms, as well as statistics and probability theory. \\n\\nFinally, it is important to have strong problem-solving and analytical skills, as well as the ability to work in a team. You should also be able to communicate complex ideas clearly and concisely. \\n\\nIf you have these skills and experience, you may be ready to pursue a career as an AI engineer. There are several ways to do this, including earning a master's or PhD in computer science or a related field, or by completing a boot camp or online course. You may also be able to gain experience in the field by working on personal projects or through internships or co-op programs.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["huggingface_llm.predict(prompt)"],"metadata":{"id":"4FUQNaiaie8p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Generate\n","\n","And as you can see below, the generate method gives more details"],"metadata":{"id":"E-8cyIKdtCmW"}},{"cell_type":"code","source":["# when using .generate you need to pass in a list\n","openai_llm.generate([prompt])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RkDejPvsgc0","executionInfo":{"status":"ok","timestamp":1695903010556,"user_tz":300,"elapsed":2377,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"dfc526d3-d167-4824-8595-e74c31f86753"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LLMResult(generations=[[Generation(text='\\n\\nHarpreet Sahota, the legendary data scientist, was born and raised in Sacramento, CA. She is now making her mark in the data science world, inspiring many in her hometown.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'completion_tokens': 40, 'total_tokens': 66, 'prompt_tokens': 26}, 'model_name': 'text-davinci-003'}, run=[RunInfo(run_id=UUID('429f6d3f-37c3-43a4-a7f4-e1b829690d9a'))])"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Compare model outputs"],"metadata":{"id":"ZQU-SamRilkh"}},{"cell_type":"code","source":["from langchain.model_laboratory import ModelLaboratory\n","\n","model_lab = ModelLaboratory.from_llms([openai_llm, cohere_llm, huggingface_llm])\n","\n","model_lab.compare(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z83ZqOmHhfW0","executionInfo":{"status":"ok","timestamp":1695902804359,"user_tz":300,"elapsed":13647,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"52347c0a-7cff-4b0f-c1c4-866617322c00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mInput:\u001b[0m\n","How do I become an AI Engineer?\n","\n","\u001b[1mOpenAI\u001b[0m\n","Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n","\u001b[36;1m\u001b[1;3m\n","\n","1. Obtain a bachelor‚Äôs degree in computer science, software engineering, mathematics, physics, or another related field.\n","\n","2. Gain experience with AI-related technologies, such as machine learning and deep learning.\n","\n","3. Become proficient in coding languages, such as Python, C++, and R.\n","\n","4. Build a portfolio of projects that demonstrate your AI engineering skills.\n","\n","5. Pursue a master‚Äôs degree in AI engineering or a related field.\n","\n","6. Familiarize yourself with industry trends and developments in AI technology.\n","\n","7. Consider obtaining certifications or attending workshops that can help you develop the necessary skills.\n","\n","8. Network with other AI engineers and stay up-to-date on the latest advancements in the field.\u001b[0m\n","\n","\u001b[1mCohere\u001b[0m\n","Params: {'model': None, 'max_tokens': 256, 'temperature': 0.75, 'k': 0, 'p': 1, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'truncate': None}\n","\u001b[33;1m\u001b[1;3m There is no single path to becoming an AI engineer, but there are several steps you can take to help you get started in the field. Here are a few suggestions:\n","\n","1. Education: A strong foundation in computer science and mathematics is essential for AI engineering. Consider pursuing a degree in computer science, data science, or a related field. You may also want to consider taking online courses or boot camps to gain additional skills and knowledge.\n","\n","2. Experience: Experience in software development and machine learning is crucial for AI engineering. Consider working on personal projects or internships to gain hands-on experience with programming languages, algorithms, and data structures. You may also want to consider joining a hackathon or participating in online coding challenges to showcase your skills.\n","\n","3. Specialization: AI engineering is a broad field, so it's important to focus on a specific area of interest. Consider specializing in a particular area of AI, such as natural language processing, computer vision, or machine learning. This will help you stand out in the job market and make you more attractive to potential employers.\n","\n","4. Networking: Networking is an important part of any job search, and AI engineering is no exception. Consider joining professional organizations, attending conferences and meetups, and connecting\u001b[0m\n","\n"]}]},{"cell_type":"markdown","source":["# Working with Chat models\n","\n","We'll stick to the OpenAI chat models for this section.\n","\n","The chat model interface is based around messages rather than raw text.\n","\n","The types of messages currently supported in LangChain are `AIMessage`, `HumanMessage`, `SystemMessage`."],"metadata":{"id":"tcCiP-OptmFx"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","\n","from langchain.schema import (\n","    AIMessage,\n","    HumanMessage,\n","    SystemMessage\n",")\n","\n","llm = OpenAI(model_name=\"gpt-3.5-turbo\")\n","chat = ChatOpenAI()\n","\n","messages = [\n","    SystemMessage(content=\"You are a tough love career coach who gets to the point and pushes your mentees to be their best.\"),\n","    HumanMessage(content=\"How do I become an AI engineer?\")\n","]\n","\n","chat(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdonQfiRtmQa","executionInfo":{"status":"ok","timestamp":1695903329436,"user_tz":300,"elapsed":20109,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"4db3119a-8f8e-42ac-8c89-c64199284e0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Becoming an AI engineer requires dedication, hard work, and a solid skill set. Here's a roadmap to get you started:\\n\\n1. Education: Pursue a degree in computer science, data science, or a related field. Get a strong foundation in mathematics, statistics, and programming languages like Python.\\n\\n2. Specialize: Focus on artificial intelligence, machine learning, and deep learning. Take advanced courses in these areas and gain a deep understanding of algorithms, data structures, and optimization techniques.\\n\\n3. Projects: Build a portfolio of AI projects to showcase your skills. Start with small projects and gradually work on more complex ones. Collaborate with others to gain experience in real-world scenarios.\\n\\n4. Practical Experience: Look for internships or entry-level positions in companies that work on AI projects. Gain hands-on experience, learn from experts, and apply your skills to solve real-world problems.\\n\\n5. Continuous Learning: AI is an ever-evolving field, so stay updated with the latest trends, techniques, and tools. Attend workshops, conferences, and online courses to expand your knowledge and stay competitive.\\n\\n6. Networking: Build a strong professional network in the AI community. Attend industry events, join online forums, and connect with experts. Networking can open doors to job opportunities and collaborations.\\n\\n7. Showcasing Skills: Create a strong online presence by contributing to AI communities, publishing research papers, and participating in AI competitions. This will establish you as a credible AI engineer.\\n\\n8. Job Search: Tailor your resume to highlight your AI expertise and showcase your relevant projects. Apply to companies that work on AI technologies and demonstrate your passion, skills, and potential during interviews.\\n\\nRemember, becoming an AI engineer requires continuous learning and perseverance. Be prepared to put in the effort and push yourself beyond your limits. Good luck!\", additional_kwargs={}, example=False)"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["## Prompts:\n","\n","1. **Language models (LLMs)** require prompts to function.\n","\n","2. A prompt is a set of instructions or input provided to guide the model's response.\n","\n","3. The output from a prompt can be answers, sentence completions, or conversation responses.\n","\n","4. A well-constructed prompt template has the following parts:\n","   - **Instructions**: Define the model's response/behavior.\n","   - **Context**: Provides additional information, sometimes with examples.\n","   - **User Input**: The actual question or input from the user.\n","   - **Output Indicator**: Marks the beginning of the model's response.\n","\n","\n","## What is a Prompt Template?\n","\n","A `PromptTemplate` allows creating a template string with placeholders, like `{adjective}` or `{content}` that can be formatted with input values to create the final prompt string.\n","\n","It's a reproducible way to generate, share, and reuse prompts.\n","\n","Contains:\n","   - A text string (template) that takes inputs and produces a prompt for the LLM.\n","   - Instructions for the LLM.\n","   - Few-shot examples to enhance the model's response.\n","   - A question for the language model."],"metadata":{"id":"Betwnqk9iUfb"}},{"cell_type":"code","source":["from langchain import PromptTemplate, OpenAI\n","\n","# Define a simple prompt template as a Python string\n","\n","prompt_template = PromptTemplate.from_template(\"\"\"\n","Human: What is the capital of {place}?\n","AI: The capital of {place} is {capital}\n","\"\"\")\n","\n","prompt = prompt_template.format(place=\"California\", capital=\"Sacramento\")\n","\n","print(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqqdHckcjcwh","executionInfo":{"status":"ok","timestamp":1695902874208,"user_tz":300,"elapsed":217,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"3cd650cc-8282-44bd-b7b5-4ac862ac5fba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Human: What is the capital of California?\n","AI: The capital of California is Sacramento\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:24: UserWarning: Importing PromptTemplate from langchain root module is no longer supported.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:24: UserWarning: Importing OpenAI from langchain root module is no longer supported.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# No Input Variable\n","no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a joke.\")\n","print(no_input_prompt.format())\n","\n","# One Input Variable\n","one_input_prompt = PromptTemplate(input_variables=[\"adjective\"], template=\"Tell me a {adjective} joke.\")\n","print(one_input_prompt.format(adjective=\"funny\"))\n","\n","# Multiple Input Variables\n","multiple_input_prompt = PromptTemplate(\n"," input_variables=[\"adjective\", \"content\"],\n"," template=\"Tell me a {adjective} joke about {content}.\"\n",")\n","\n","multiple_input_prompt = multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")\n","print(multiple_input_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDF6qagNtLyr","executionInfo":{"status":"ok","timestamp":1695903176896,"user_tz":300,"elapsed":285,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"232dd04e-34e6-450b-b936-a6f7174d2a0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tell me a joke.\n","Tell me a funny joke.\n","Tell me a funny joke about chickens.\n"]}]},{"cell_type":"markdown","source":["Pass a prompt template to an LLM"],"metadata":{"id":"49tpjrJ4sDiK"}},{"cell_type":"code","source":["llm = OpenAI()\n","\n","prompt_template = PromptTemplate.from_template(\n","    template=\"Write a {length} story about: {content}\"\n",")\n","\n","prompt = prompt_template.format(\n","    length=\"2-sentence\",\n","    content=\"Sacramento, CA, the hometown of the legendary data scientist, Harpreet Sahota\"\n",")\n","\n","response = llm.predict(\n","    text=prompt\n",")\n","\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWt4eqPYsMOe","executionInfo":{"status":"ok","timestamp":1695903098195,"user_tz":300,"elapsed":1650,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"d866bbb0-e51d-4b4f-d92c-dd3f94ecaee6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","When Harpreet Sahota was growing up in Sacramento, CA, little did he know that he would one day become a legendary data scientist. Now, his hometown is proud to have him as one of their own.\n"]}]},{"cell_type":"markdown","source":["# Output parsers\n","\n","Depending on the downstream uses, raw text from a language model might not be what you need.\n","\n","Output parsers are classes in Langchain that help structure the text responses from language models into more useful formats. Output parsers allow you to convert the text into JSON, Python dataclasses, database rows, and more.\n","\n","## What are they used for?\n","\n","Output parsers have two main uses:\n","\n","1) Convert unstructured text into structured data. For example, parsing text into a JSON or Python object.\n","\n","2) Inject instructions into prompts to tell language models how to format their responses. The parser can provide a `get_format_instructions()` method that returns text for the prompt."],"metadata":{"id":"KbA8VUansNbk"}},{"cell_type":"code","source":["from langchain.output_parsers import CommaSeparatedListOutputParser\n","from langchain.prompts import PromptTemplate\n","from langchain.llms import OpenAI\n","\n","from langchain.output_parsers.list import ListOutputParser"],"metadata":{"id":"qSgj7TzytcXb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Without parsing output"],"metadata":{"id":"xxErRRo8uNZ8"}},{"cell_type":"code","source":["llm = OpenAI()\n","\n","prompt = PromptTemplate(\n","    template=\"List 3 {things}\",\n","    input_variables=[\"things\"])\n","\n","llm.predict(text=prompt.format(things=\"sports that don't use balls\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"ImaVmsMJuPNC","executionInfo":{"status":"ok","timestamp":1695903449083,"user_tz":300,"elapsed":2199,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"e79e57cd-5931-4589-f75b-31bf92af224e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\n1. Swimming \\n2. Running \\n3. Rock Climbing'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["Instantiate output parser"],"metadata":{"id":"miBkqzg6uPXg"}},{"cell_type":"code","source":["output_parser = CommaSeparatedListOutputParser()\n","\n","format_instructions = output_parser.get_format_instructions()\n","\n","print(format_instructions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYr5wUwSuTA0","executionInfo":{"status":"ok","timestamp":1695903464561,"user_tz":300,"elapsed":211,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"08a12f7a-e52a-499d-deff-282e01366d71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"]}]},{"cell_type":"markdown","source":["Now let's see how to use the parsers instructions in the prompt"],"metadata":{"id":"EpCtrfZMuTjW"}},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"List 3 {things}.\\n{format_instructions}\",\n","    input_variables=[\"things\"],\n","    partial_variables={\"format_instructions\": format_instructions})\n","\n","output = llm.predict(text=prompt.format(things=\"sports that don't use balls\"))\n","\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PacmGGFwub6P","executionInfo":{"status":"ok","timestamp":1695903500945,"user_tz":300,"elapsed":1764,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"051c32dd-69c0-4238-e2ea-c92de6498372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Cricket, Golf, Archery\n"]}]},{"cell_type":"markdown","source":["Finally, we can parse the output to a list (Python object)"],"metadata":{"id":"O-jtHlteussa"}},{"cell_type":"code","source":["output_parser.parse(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83e3itBiucJb","executionInfo":{"status":"ok","timestamp":1695903563178,"user_tz":300,"elapsed":223,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"f57fcfb6-ea79-4f6c-c4e1-ce34efe4b372"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Cricket', 'Golf', 'Archery']"]},"metadata":{},"execution_count":40}]}]}